[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IS415-GAA-JS",
    "section": "",
    "text": "this is the course website of IS415. you will find my coursework published on this website"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "title": "In-class_Ex03",
    "section": "",
    "text": "Show the code\ninstall.packages(\"maptools\", repos = \"https://packagemanager.posit.co/cran/2023-10-13\")\n\n\n\n\nShow the code\npacman::p_load(maptools, sf, raster, spatstat, tmap, tidyverse)\n\n\nImporting the data we currently have: Take not that the Child Care Service data is in WGS84 projection, so we need to use st_transform(crs=3414) to change it to the correct projection system All projection should be standardised!\n\n\nShow the code\nchildcare_sf <- st_read(\"data/geospatial/ChildCareServices.geojson\") %>%\n  st_transform(crs = 3414)\n\n\nReading layer `ChildCareServices' from data source \n  `C:\\jaymieseet\\IS415-GAA-JS\\In-class_Ex\\In-class_Ex03\\data\\geospatial\\ChildCareServices.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1925 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nShow the code\nmpsz_sf <- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\jaymieseet\\IS415-GAA-JS\\In-class_Ex\\In-class_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\nShow the code\nmpsz_sf\n\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nWe can derive the CostalOutline from the Master Plan 2014 Subzone data\n\n\nShow the code\nplot(mpsz_sf)\n\n\n\n\n\nBy plotting mpsz_sf, we can see the map that we want to derive the CostalOutline from. In order to get the outline, we have to dissolve away the boundaries of the subzones (Combine the polygons together) *\n\nst_combine() does not dissolve the boundary, but only combines the polygons (the output is one whole giant polygon)\nst_union() dissolves the boundary, and we can choose the specific attributes that we want to dissolve (eg. by subzones or by planning area). The polygons are still individual as they are not combined.\n\n\n\nShow the code\nsg_sf <- mpsz_sf %>%\n  st_union()\n\n\nNow the polygons should be combined!\n\n\nShow the code\nplot(sg_sf)\n\n\n\n\n\n“Spatstat” is an R package designed for analyzing spatial point patterns, commonly encountered in fields like ecology, epidemiology, and geospatial statistics. In the context of spatstat, “ppp” stands for “point pattern,” and it is a specific format within spatstat used to represent point patterns.\nWhen working with spatstat, your spatial data needs to be converted into the “ppp” format, which is the expected input format for many spatstat functions. This format includes not just the coordinates of points but also additional information about the pattern, such as marks assigned to each point.\nConvert the sf dataframe to ppp that conforms to the spastat standard Check the duplication in a ppp object! When dealing with georeferenced locations using postal code, grouping of multiple locations under a single postal code is possible.\n\n\nShow the code\nchildcare_ppp <- as.ppp(childcare_sf)\nany(duplicated(childcare_ppp))\n\n\n[1] FALSE\n\n\nCreating owin object: sf method\n\n\nShow the code\nsg_owin <- as.owin(sg_sf)\n\n\nNote that it has to be in sf format. Anything that uses the ‘as’ function needs to be in sf format.\nThe code chunk below will be used to extract the target planning areas use the sf layer to use diplyr filter\n\n\nShow the code\npg <- mpsz_sf %>%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm <- mpsz_sf %>%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck <- mpsz_sf %>%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw <- mpsz_sf %>%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\n\nPlotting out the target planning areas\n\n\nShow the code\npar(mfrow=c(2,2))\nplot(pg, main = \"Punggol\")\n\n\n\n\n\nShow the code\nplot(tm, main = \"Tampines\")\n\n\n\n\n\nShow the code\nplot(ck, main = \"Choa Chu Kang\")\n\n\n\n\n\nShow the code\nplot(jw, main = \"Jurong West\")\n\n\n\n\n\n‘main’ is used to label the planning areas\n\n\nShow the code\nclass(mpsz_sf)\n\n\n[1] \"sf\"         \"data.frame\"\n\n\n\n\nShow the code\npacman::p_load(sp, sf, rgdal, spNetwork, tmap)\nnetwork <- st_read(dsn=\"data/geospatial\", \n                   layer=\"Punggol_St\")\n\n\nReading layer `Punggol_St' from data source \n  `C:\\jaymieseet\\IS415-GAA-JS\\In-class_Ex\\In-class_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\n\n\nShow the code\nchildcare <- st_read(dsn=\"data/geospatial\",\n                     layer=\"Punggol_CC\")\n\n\nReading layer `Punggol_CC' from data source \n  `C:\\jaymieseet\\IS415-GAA-JS\\In-class_Ex\\In-class_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\n\n\nAlways plot the dots (points) then the lines (polygons), if not the polygons will block the points\n\n\nShow the code\ntmap_mode('view')\ntm_shape(childcare) + \n  tm_dots() + \n  tm_shape(network) +\n  tm_lines()\n\n\n\n\n\n\n\n\n\nShow the code\nlixels <- lixelize_lines(network, \n                         700, \n                         mindist = 350)\n\n\nLength of a lixel, lx_length is set to 750cm Minimum length of a lixel, mindist is set to 375cm (it should be half of the length)\ndensities <- nkde(network, events = childcare, w = rep(1,nrow(childcare)), samples = samples, kernel_name = “quartic”, bw = 300, div= “bw”, method = “simple”, digits = 1, tol = 1, grid_shape = c(1,1), max_depth = 8, agg = 5, #we aggregate events within a 5m radius (faster calculation) sparse = TRUE, verbose = FALSE)\nshows us which road segment explicitly have more childcare centres instead of the general density of the area. It is useful for decision making, for example, deciding where to place traffic crossings to minimise road congestion."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "hunan <- left_join(hunan,hunan2012)%>%\n  select(1:4, 7, 15)\n\nwhen we left_join, it append everything from the hunan2012 to hunan. the select allow us to explicitly select the columns that we want. simeplfeatures have a geometric column, so if we inspect the hunan data now, we have 7 variables.\n\nbasemap <- tm_shape(hunan) +\n  tm_polygons() +\n  tm_text(\"NAME_3\", size=0.5)\n\ngdppc <- qtm(hunan, \"GDPPC\")\ntmap_arrange(basemap, gdppc, asp=1, ncol=2)\n\n\n\n\nqtm is a quick way to view our map data (plotting hunan and GDPPC), do not need to specify any classification methods. But a better way to plot a thematic map is to use all the tmap properties to define the style.\nThe plotting does not start until tm_polygons(). tm_text() is to add labelling on your map. tmap_arrange() allows us to put all the maps together in one whole view.\n\nwm_q <- poly2nb(hunan, queen=TRUE)\n\nwm_q is a list and this list indicates the neighbours of each polygon.\n\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThis shows the summary of the lists. even though the average number of links have a decimal place, the number of actual neighbours should be an integer, so we can round up or round down.\nThe top row of numbers is the number of neighbours and the bottom row is the number of geographical area. eg. there is only 1 geographical area with 11 neighbours.\nArea 30 and 65 have the least number of links. Area 85 have the most number of links.\n\nwm_r <- poly2nb(hunan, queen=FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\n\n#coords <- coordinates(hunan)\nk1 <- knn2nb(knearneigh(coords))\nk1dists <- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  13.86   28.12   34.99   36.19   44.54   67.50 \n\n\nreturns the neighbour list, based on their distance. Input is k1 coordinates.\nuse the largest distance to determine the cut off, always round up and not round down to not miss out any points.In this case, our cut-off distance will be 62.\n\nwm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 49 \nNumber of nonzero links: 226 \nPercentage nonzero weights: 9.412745 \nAverage number of links: 4.612245 \n2 regions with no links:\n1 21\n4 disjoint connected subgraphs\n\n\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE)\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\n\n\n\n\n\nb_weights <- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 <- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nIn-class exercise\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr,GWmodel)\n\n\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\jaymieseet\\IS415-GAA-JS\\In-class_Ex\\In-class_Ex04\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")\nhunan <- left_join(hunan,hunan2012)%>%\n  select(1:4, 7, 15)\n\n\nwn_d62 <- dnearneigh(coords,0,62, longlat = TRUE)\nhunan_sp <- hunan %>%\n  as_Spatial()\n\nit is a complex data model and there is no geometric data\n\ngwstat <- gwss(data = hunan_sp,\n               vars = \"GDPPC\",\n               bw=6,\n               kernel = \"bisquare\",\n               adaptive = TRUE,\n               longlat = T)\n\nbandwidth and adaptive have to match. if adaptive = TRUE, bw = 6 (neighbours), if it is false, bw will equal to 62 (kilometres)\nplot the map and try with fixed distance"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "title": "In-Class Exercise 5",
    "section": "",
    "text": "Exploring an alternative R package to spdep."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#importing-geospatial-data",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#importing-geospatial-data",
    "title": "In-Class Exercise 5",
    "section": "Importing Geospatial Data",
    "text": "Importing Geospatial Data\n\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\jaymieseet\\IS415-GAA-JS\\In-class_Ex\\In-class_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\nWe should always check the data in our R environment. The geometry of this layer should be POLYGON."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#import-attribute-data",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#import-attribute-data",
    "title": "In-Class Exercise 5",
    "section": "Import Attribute Data",
    "text": "Import Attribute Data\n\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nWe must check through both data to see whether there are the same fields that will allow us to do the relational join."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#performing-relational-join",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#performing-relational-join",
    "title": "In-Class Exercise 5",
    "section": "Performing Relational Join",
    "text": "Performing Relational Join\n\nhunan_GDPPC <- left_join(hunan,hunan2012) %>%\n  select(1:4, 7, 15)\n\nWe only want to keep the columns that we need for the Hunan GDPPC."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#choropleth-map-for-the-distribution-of-gdp-per-capita-hunan-province",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#choropleth-map-for-the-distribution-of-gdp-per-capita-hunan-province",
    "title": "In-Class Exercise 5",
    "section": "Choropleth Map for the Distribution of GDP Per Capita, Hunan Province",
    "text": "Choropleth Map for the Distribution of GDP Per Capita, Hunan Province\ntm_shape already takes in the spatial data, since our data is already in sf, we do not need to specify tm_shape(hunan$geometry) as the geometry layer will already be read.\n\ntmap_mode(\"plot\")\ntm_shape(hunan_GDPPC) +\n  tm_fill(\"GDPPC\",\n          style = \"quantile\",\n          palette = 'Blues',\n          title='GDPPC') +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#computing-global-moranl",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#computing-global-moranl",
    "title": "In-Class Exercise 5",
    "section": "Computing Global Moran’l",
    "text": "Computing Global Moran’l\n\nmoranI <- global_moran(wm_q$GDPPC, \n                       wm_q$nb, \n                       wm_q$wt) \nglimpse(moranI)\n\nList of 2\n $ I: num 0.301\n $ K: num 7.64"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#performing-global-morani-test",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#performing-global-morani-test",
    "title": "In-Class Exercise 5",
    "section": "Performing Global Moran’I test",
    "text": "Performing Global Moran’I test\n\nglobal_moran_test(wm_q$GDPPC,\n                  wm_q$nb,\n                  wm_q$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#performing-global-morani-permutation-test",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#performing-global-morani-permutation-test",
    "title": "In-Class Exercise 5",
    "section": "Performing Global Moran’I permutation test",
    "text": "Performing Global Moran’I permutation test\n\nglobal_moran_perm(wm_q$GDPPC,\n                  wm_q$nb,\n                  wm_q$wt,\n                  nsim = 99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value < 2.2e-16\nalternative hypothesis: two.sided"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html",
    "title": "In-Class Exercise 7",
    "section": "",
    "text": "pacman::p_load(sp, spdep, tmap, sf, ClustGeo, \n               ggpubr, cluster, factoextra, NbClust,\n               heatmaply, corrplot, psych, tidyverse, GGally)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#data-preparation",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#data-preparation",
    "title": "In-Class Exercise 7",
    "section": "Data Preparation",
    "text": "Data Preparation\n\nict_derived <- ict %>%\n  mutate(`RADIO_PR` = `Radio`/`Total households`*1000) %>%\n  mutate(`TV_PR` = `Television`/`Total households`*1000) %>%\n  mutate(`LLPHONE_PR` = `Land line phone`/`Total households`*1000) %>%\n  mutate(`MPHONE_PR` = `Mobile phone`/`Total households`*1000) %>%\n  mutate(`COMPUTER_PR` = `Computer`/`Total households`*1000) %>%\n  mutate(`INTERNET_PR` = `Internet at home`/`Total households`*1000) %>%\n  rename(`DT_PCODE` =`District Pcode`,`DT`=`District Name`,\n         `TS_PCODE`=`Township Pcode`, `TS`=`Township Name`,\n         `TT_HOUSEHOLDS`=`Total households`,\n         `RADIO`=`Radio`, `TV`=`Television`, \n         `LLPHONE`=`Land line phone`, `MPHONE`=`Mobile phone`,\n         `COMPUTER`=`Computer`, `INTERNET`=`Internet at home`) \n\nWe have to standardize the values (divide by total household and scale it up) to derive the ownership. Then, we rename it to make the field name more concise and easier to recognise.\nWe can create all the plots to plot the distribution of the newly derived variables. The code chunk below allows you to plot out all the variables in one view.\n\nradio <- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ntv <- ggplot(data=ict_derived, \n             aes(x= `TV_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nllphone <- ggplot(data=ict_derived, \n             aes(x= `LLPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nmphone <- ggplot(data=ict_derived, \n             aes(x= `MPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ncomputer <- ggplot(data=ict_derived, \n             aes(x= `COMPUTER_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ninternet <- ggplot(data=ict_derived, \n             aes(x= `INTERNET_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nLeft join the 2 dataframes with the unique identifier used to join both data objects is TS_PCODE. When we append all the ICT variables over, the first data file should be the geometry sf file, the second one will be the attribute data file. ‘by’ parameter defines the unique identifier, which is not necessary here since the unique identifier field has the same name, but it is good practice to define it.\nIf both files are a spatial file, we should use st_join() instead. Left join allows the use the sf for only one file.\n\nshan_sf <- left_join(shan_sf, \n                     ict_derived, by=c(\"TS_PCODE\"=\"TS_PCODE\"))\n  \nwrite_rds(shan_sf, \"data/rds/shan_sf.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#hierarchy-cluster-analysis",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#hierarchy-cluster-analysis",
    "title": "In-Class Exercise 7",
    "section": "Hierarchy Cluster Analysis",
    "text": "Hierarchy Cluster Analysis\n\ncluster_vars <- shan_sf %>%\n  st_set_geometry(NULL) %>%\n  select(\"TS.x\", \"RADIO_PR\", \"TV_PR\", \"LLPHONE_PR\", \"MPHONE_PR\", \"COMPUTER_PR\")\nhead(cluster_vars,10)\n\n        TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\n1    Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\n2    Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\n3    Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\n4   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\n5     Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\n6      Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\n7      Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\n8   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\n9  Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\n10   Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\n\nExtracting clustering variables\n\nshan_ict <- select(cluster_vars, c(2:6))\nhead(shan_ict, 10)\n\n   RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\n1  286.1852 554.1313   35.30618  260.6944    12.15939\n2  417.4647 505.1300   19.83584  162.3917    12.88190\n3  484.5215 260.5734   11.93591  120.2856     4.41465\n4  231.6499 541.7189   28.54454  249.4903    13.76255\n5  449.4903 708.6423   72.75255  392.6089    16.45042\n6  280.7624 611.6204   42.06478  408.7951    29.63160\n7  318.6118 535.8494   39.83270  214.8476    18.97032\n8  387.1017 630.0035   31.51366  320.5686    21.76677\n9  349.3359 547.9456   38.44960  323.0201    15.76465\n10 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\n\n\nData Standardisation\n\nshan_ict.std <- normalize(shan_ict)\nsummary(shan_ict.std)\n\n    RADIO_PR          TV_PR          LLPHONE_PR       MPHONE_PR     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.2544   1st Qu.:0.4600   1st Qu.:0.1123   1st Qu.:0.2199  \n Median :0.4097   Median :0.5523   Median :0.1948   Median :0.3846  \n Mean   :0.4199   Mean   :0.5416   Mean   :0.2703   Mean   :0.3972  \n 3rd Qu.:0.5330   3rd Qu.:0.6750   3rd Qu.:0.3746   3rd Qu.:0.5608  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n  COMPUTER_PR     \n Min.   :0.00000  \n 1st Qu.:0.09598  \n Median :0.17607  \n Mean   :0.23692  \n 3rd Qu.:0.29868  \n Max.   :1.00000  \n\n\n\nshan_ict.z <- scale(shan_ict)\ndescribe(shan_ict.z)\n\n            vars  n mean sd median trimmed  mad   min  max range  skew kurtosis\nRADIO_PR       1 55    0  1  -0.04   -0.06 0.94 -1.85 2.55  4.40  0.48    -0.27\nTV_PR          2 55    0  1   0.05    0.04 0.78 -2.47 2.09  4.56 -0.38    -0.23\nLLPHONE_PR     3 55    0  1  -0.33   -0.15 0.68 -1.19 3.20  4.39  1.37     1.49\nMPHONE_PR      4 55    0  1  -0.05   -0.06 1.01 -1.58 2.40  3.98  0.48    -0.34\nCOMPUTER_PR    5 55    0  1  -0.26   -0.18 0.64 -1.03 3.31  4.34  1.80     2.96\n              se\nRADIO_PR    0.13\nTV_PR       0.13\nLLPHONE_PR  0.13\nMPHONE_PR   0.13\nCOMPUTER_PR 0.13\n\n\nThe Z-score always equal to 1.\n\n\nVisualising the standardised clustering variables\nPlot the graph to see the how the use of the different standardization affects.\n\nr <- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Raw values without standardisation\")\n\nshan_ict_s_df <- as.data.frame(shan_ict.std)\ns <- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df <- as.data.frame(shan_ict.z)\nz <- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)\n\n\n\n\n\nr <- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Raw values without standardisation\")\n\nshan_ict_s_df <- as.data.frame(shan_ict.std)\ns <- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df <- as.data.frame(shan_ict.z)\nz <- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)\n\n\n\n\n\nproxmat <- dist(shan_ict, method = 'euclidean')\n\nUsing the distance metrics.\n\nhclust_ward <- hclust(proxmat, method = 'ward.D')\n\nWe can extract the clustering results and plot it into a dendrogram.\n\nplot(hclust_ward, cex = 0.6)\n\n\n\n\nFor example, if we put the cut-off at 200, we will have 2 clusters. To determine the cut-off, we should calculate the definite value.\nWe can do multiple calculations to see which one gives us the best results.\n\nm <- c( \"average\", \"single\", \"complete\", \"ward\")\nnames(m) <- c( \"average\", \"single\", \"complete\", \"ward\")\n\nac <- function(x) {\n  agnes(shan_ict, method = x)$ac\n}\n\nmap_dbl(m, ac)\n\n  average    single  complete      ward \n0.8131144 0.6628705 0.8950702 0.9427730 \n\n\n\nset.seed(12345)\ngap_stat <- clusGap(shan_ict, \n                    FUN = hcut, \n                    nstart = 25, \n                    K.max = 10, \n                    B = 50)\n# Print the result\nprint(gap_stat, method = \"firstmax\")\n\nClustering Gap statistic [\"clusGap\"] from call:\nclusGap(x = shan_ict, FUNcluster = hcut, K.max = 10, B = 50, nstart = 25)\nB=50 simulated reference sets, k = 1..10; spaceH0=\"scaledPCA\"\n --> Number of clusters (method 'firstmax'): 1\n          logW   E.logW       gap     SE.sim\n [1,] 8.407129 8.680794 0.2736651 0.04460994\n [2,] 8.130029 8.350712 0.2206824 0.03880130\n [3,] 7.992265 8.202550 0.2102844 0.03362652\n [4,] 7.862224 8.080655 0.2184311 0.03784781\n [5,] 7.756461 7.978022 0.2215615 0.03897071\n [6,] 7.665594 7.887777 0.2221833 0.03973087\n [7,] 7.590919 7.806333 0.2154145 0.04054939\n [8,] 7.526680 7.731619 0.2049390 0.04198644\n [9,] 7.458024 7.660795 0.2027705 0.04421874\n[10,] 7.377412 7.593858 0.2164465 0.04540947\n\n\n\nfviz_gap_stat(gap_stat)\n\n\n\n\nFrom her we can see that the closest optimisation difference is 5 and 6. 6 is slightly higher so we should choose 6.\nUse rect.hclust() to clearly show the clusters so we can also see which cluster has the most amount of members.\n\nplot(hclust_ward, cex = 0.6)\nrect.hclust(hclust_ward, \n            k = 6, \n            border = 2:5)\n\n\n\n\nUse as.factor() to convert it into a factor data type and arranged in a ordinal scale.\n\ngroups <- as.factor(cutree(hclust_ward, k=6))\n\nUse cbind() to append the 2 dataframes instead of left_join() because there are no unique identifers. However, if we perform any form of sorting, the sequence change and we cannot use cbind().\n\nshan_sf_cluster <- cbind(shan_sf, as.matrix(groups)) %>%\n  rename(`CLUSTER`=`as.matrix.groups.`)\n\n\nqtm(shan_sf_cluster, \"CLUSTER\")\n\n\n\n\nSince it is in the class factor, the numbers are all treated as individual classes. If it was in the numeric class, it would become a range.\nPreviously, poly2nb() only worked with sp objects, but the latest version does not require us to convert it to sp and we can just use the sf class.\n\nshan.nb <- poly2nb(shan_sf)\nsummary(shan.nb)\n\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\n\nSince it is an sf object, we can use the plot() function to show the map.\n\nplot(st_geometry(shan_sf), border=grey(.5))\npts <- st_coordinates(st_centroid(shan_sf))\nplot(shan.nb,\n     pts,\n     col=\"blue\",\n     add=TRUE)\n\n\n\n\n\n\n\nIt is not enough to just identify the clusters, we should plot out the clusters to evaluate them."
  },
  {
    "objectID": "In-class_Ex02/In-class_Ex02.html",
    "href": "In-class_Ex02/In-class_Ex02.html",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "The packages used for this exercise are:\n\nlubridate\narrow\ntidyverse\ntmap\nsf\n\n\n\nShow the code\npacman::p_load(sf, tmap, tidyverse, lubridate, arrow)\n\n\nImporting GrabPosisi Dataset with arrow package\n\n\nShow the code\ndf <- read_parquet(\"data/GrabPosisi/part-00000-8bbff892-97d2-4011-9961-703e38972569.c000.snappy.parquet\")\n\n\nConverting the data type of pingtimestamp from character to date-time\nThis code overwrites the field characteristics in the df. Before, the data type in int, but after this code chuck, it should change to POSIXct\n\n\nShow the code\ndf$pingtimestamp <- as_datetime(df$pingtimestamp)\n\n\nExtracting the trip origin location\n\nGroup them according to the trajectory.\nArrange them according to the pingtimestamp, sorted in ascending order\nEvery trip that we generate, the first one should be the origin, so filter row_number()==1\nMutate to derive new variables, weekday, start_hr and day.\n\nwday, hour and mdaylabel = true is to label the day of the week, if not it will just be labelled as 1, 2, 3, 4\nfactor to put it into ordinal scale (hour, minute, second)\n\n*More information on the parameters found on the tidyverse reference page\n\n\n\nShow the code\norigin_df <- df%>%\n  group_by(trj_id) %>%\n  arrange(pingtimestamp) %>%\n  filter(row_number()==1) %>%\n  mutate(weekday = wday(pingtimestamp, \n                        label=TRUE, \n                        abbr=TRUE), \n         start_hr = factor(hour(pingtimestamp)), \n         day= factor(mday(pingtimestamp)))\n\n\nExtracting trip destination locations\nSimilar to the code before, but arrange it in descending order\n\n\nShow the code\ndestination_df <- df%>%\n  group_by(trj_id) %>%\n  arrange(desc(pingtimestamp)) %>%\n  filter(row_number()==1) %>%\n  mutate(weekday = wday(pingtimestamp, \n                        label=TRUE, \n                        abbr=TRUE), \n         end_hr = factor(hour(pingtimestamp)), \n         day= factor(mday(pingtimestamp)))\n\n\nSave it in r datafile format because it will save all the object class eg. the weekday, start_hr fields that we created, so that we can reuse it in the future.\n\n\n\nWhen we want to restart on this file, import back the data\n\n\nShow the code\norigin_df <- read_rds(\"data/rds/origin_df.rds\")\ndestination_df <- read_rds(\"data/rds/destination_df.rds\")"
  }
]